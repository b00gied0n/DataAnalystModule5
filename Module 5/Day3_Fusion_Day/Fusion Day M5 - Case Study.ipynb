{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Goal\n",
    "To apply linear regression in Python to determine the predicted demand for the London cycle hire scheme for the next 12-month period. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the datasets\n",
    "\n",
    "\n",
    "There are three datasets in total. These are:  \n",
    "\n",
    "bike_data_2021_part1.xlsx  \n",
    "bike_data_2021_part2.xlsx  \n",
    "Bike_data_new.xlsx  \n",
    "\n",
    "The datasets track specific weather conditions that may affect the dependent variable. There are 14 variables included in the datasets; these are listed below. The bikecount variable is the dependent variable.   \n",
    "\n",
    "The three datasets answer the business question:  \n",
    "‘What is the predicted demand for the London cycle hire scheme for the next 12-month period?’ \n",
    "\n",
    "Variables\n",
    "\n",
    "    1.\ttimestamp – a unique date and time stamp\n",
    "    2.\tyear - categorical field showing the year 2021\n",
    "    3.\tseason - categorical field showing meteorological seasons: \n",
    "            •\tSpring (March-May)\n",
    "            •\tSummer (June-August)\n",
    "            •\tAutumn (September-November)\n",
    "            •\tWinter (December-February)\n",
    "    4.\tmonth - categorical field showing the months: January-December\n",
    "            •\t1 = January \n",
    "            •\t2 = February \n",
    "            •\t3 = March\n",
    "            •\t4 = April \n",
    "            •\t5 = May\n",
    "            •\t6 = June \n",
    "            •\t7 = July \n",
    "            •\t8 = August \n",
    "            •\t9 = September \n",
    "            •\t10 = October\n",
    "            •\t11 = November \n",
    "            •\t12 = December\n",
    "    5.\tday – categorical field showing the day of the week: Monday-Sunday\n",
    "            •\t1 = Monday\n",
    "            •\t2 = Tuesday\n",
    "            •\t3 = Wednesday\n",
    "            •\t4 = Thursday\n",
    "            •\t5 = Friday\n",
    "            •\t6 = Saturday\n",
    "            •\t7 = Sunday\n",
    "    6.\thour - categorical field showing the hours from 0-23\n",
    "    7.\tisholiday - category field that shows whether or not the day is a public holiday\n",
    "            •\t1 = holiday\n",
    "            •\t0 = non holiday\n",
    "    8.\tisweekend - categorical field that shows whether the day is a weekend or weekday\n",
    "            •\t1 = weekend\n",
    "            •\t0 = weekday  \n",
    "    9.\tweathercode - categorical field showing the days weather status\n",
    "            •\t1 = mostly clear but have some areas with patches of fog/haze\n",
    "            •\t2 = scattered clouds or few clouds\n",
    "            •\t3 = Broken clouds\n",
    "            •\t4 = Cloudy\n",
    "            •\t7 = Rain/ light Rain shower\n",
    "            •\t10 = Rain with thunderstorm\n",
    "            •\t26 = Snowfall\n",
    "            •\t94 = Freezing Fog\n",
    "    10.\tt1 – numerical field showing the real temperature in degrees Celsius  \n",
    "    11.\tt2 – numerical field showing the \"feels like\" temperature in degrees Celsius   \n",
    "    12.\thumidity - numerical field showing the humidity in percentage  \n",
    "    13.\twind - numerical field showing the wind speed in km/h  \n",
    "    14.\tbikecount - numerical field showing the the count of new bike shares  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process map\n",
    "Below illustrates the process used during this lab.\n",
    "\n",
    " \n",
    " \n",
    "TASK 2 - INVENTORY ANALYSIS\n",
    "    \n",
    "SECTION A - IMPORT & COMBINE DATA\n",
    "    \n",
    "    A.1 Access to Jupyter Notebook (COMPLETED)\n",
    "    A.2 Set default folder (COMPLETED)\n",
    "    A.3 Open file \"Module 5 Fusion Day.ipynb\" (COMPLETED)\n",
    "    A.4 Install Python Libraries\n",
    "    A.5 Import data \n",
    "    A.6 Combine datasets \n",
    "\n",
    "SECTION B - DATA PREPARATION\n",
    "    \n",
    "    B.1 Data Quality Checks\n",
    "        B.1.1 View sample of data \n",
    "        B.1.2 Shape of data\n",
    "        B.1.3 Duplicate rows\n",
    "        B.1.4 Missing data\n",
    "    B.2 Data Cleansing\n",
    "        B.2.1 Convert variables to appropriate data types  \n",
    "        B.2.2 Remove duplicate rows\n",
    "        B.2.3 Interpolate using median \n",
    " \n",
    "SECTION C - EXPLANATORY DATA ANALYSIS & VISUALISATION\n",
    "    \n",
    "    C.1 Aggregation - Calculate total & avg bike shares\n",
    "    C.2 Distribution - Calculate total & avg bike shares by: \n",
    "        C.2.1 Season \n",
    "        C.2.2 Month\n",
    "        C.2.3 Day of week\n",
    "        C.2.4 Day of week for most popular month\n",
    "        C.2.5 Calculate All descriptive stats (for numerical variables only)\n",
    "        C.2.6 Is bike shares distribution normal or skewed?\n",
    "    C.3 Correlation\n",
    "        C.3.1 Correlation Matrix\n",
    "        C.3.2 Note correlated variables \n",
    "    C.4 Visualisations\n",
    "        C.4.1 Create a jointplot\n",
    "        C.4.2 Create a lineplot\n",
    "        C.4.3 Create a pairgrid\n",
    "        C.4.4 Note findings\n",
    "\n",
    "SECTION D - PREDICTIVE MODELLING (REGRESSION)   \n",
    "    \n",
    "    D.1 Pre-processing\n",
    "        D.1.1 Remove variables \"timestamp\" & \"year\"\n",
    "        D.1.2 Encode categorical data \n",
    "    D.2 Train/Test Split (70%/30%) \n",
    "        D.2.1 Split df dataset to X & Y datasets \n",
    "\t\tD.2.2 Perform 70:30 random split (use \"random_state=1\")\n",
    "    D.3 Build Linear Regression\n",
    "\t\tD.3.1 Save the regression function \"LinearRegression()\" into a container called \"model\" \n",
    "\t\tD.3.2 Fit the regression into the training data \n",
    "    D.4 Evaluate (training dataset)\n",
    "        D.4.1 Identify regression intercept\n",
    "\t\t\tD.4.1a Reformat intercept into a dataframe\t\n",
    "        D.4.2 Identify regression coefficients\n",
    "\t\t\tD.4.2a Reformat coefficients into a dataframe\n",
    "    D.5 Run Model on Testing Dataset\n",
    "    D.6 Calculate R-squared and RMSE from D.5\n",
    "\n",
    "SECTION E - INTERPRET RESULTS \n",
    "\n",
    "\n",
    "TASK 3 - MODEL PREDICTIONS \n",
    "\n",
    "    1. IMPORT NEW DATA 'bike_data_new.xlsx'\n",
    "    2. DATA QUALITY CHECKS\n",
    "    3. DATA CLEANSING\n",
    "        3.1 Remove duplicates\n",
    "        3.2 Remove missing data\n",
    "        3.3 Make a copy of dataset \n",
    "        3.4 Convert variables to appropriate data types\n",
    "    4. PRE-PROCESSING\n",
    "        4.1 Remove variables \"timestamp\" & \"year\"\n",
    "        4.2 Encode categorical data\n",
    "    5. PREDICTION\n",
    "        5.1 Use model to predict bike shares\n",
    "        5.2 Combine predicted bikeshares from 5.1 with the new data ('bike_data_new.xlsx')\n",
    "\t\t\t5.2.1 Reformat predictions into a dataframe called 'dfr' \n",
    "\t\t\t5.2.2 Create a new dataframe that joins 'dfr' to the 'dfp_copy'  \n",
    "    6. SAVE PREDICTIONS (into csv)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECTION A - IMPORT & COMBINE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   A.1 Access to Jupyter Notebook (COMPLETED)\n",
    "#   A.2 Set default folder (COMPLETED)\n",
    "#   A.3 Open file \"Module 5 Fusion Day.ipynb\" (COMPLETED)#### A.5 IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.4 Install Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN/EXCEUTE THE ENTIRE CELL\n",
    "\n",
    "# INSTALL LIBRARIES\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install scikit-learn\n",
    "#!pip install scipy\n",
    "#!pip install seaborn\n",
    "#!pip install matplotlib#### Import Python Libraries\n",
    "\n",
    "\n",
    "# IMPORT LIBRARIES\n",
    "# These libraries are commonly used in data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "\n",
    "# Import different modules from the sklearn library to build and evaluate the linear regression model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Import matplotlib and seaborn libraries for data visualisation \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Switch off unnecessary warning messages \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.5 IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from an \"bike_data_2021_part1.xlsx\" file and save that data into a dataframe called \"df1\"\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from an \"bike_data_2021_part2.xlsx\" file and save that data into a dataframe called \"df2\"\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.6 COMBINE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Join data from df1 and df2, and save that data into a dataframe called \"df\" - use variable \"timestamp\" as the join key\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECTION B - DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1 Data Quality Checks\n",
    "\n",
    "        B.1.1 View sample of data \n",
    "        B.1.2 Shape of data\n",
    "        B.1.3 Duplicate rows\n",
    "        B.1.4 Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.1.1 VIEW SAMPLE OF DATA\n",
    "\n",
    "# Question 1: Use the right function to view top 5 records\n",
    "\n",
    "#Answer:\n",
    "\n",
    "\n",
    "\n",
    "# Question 2: View last 5 records\n",
    "\n",
    "#Answer:\n",
    "\n",
    "\n",
    "\n",
    "# Question 3: View top 3 records\n",
    "\n",
    "#Answer:\n",
    "\n",
    "\n",
    "\n",
    "# Question 4: View last 3 records\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.1.2 SHAPE OF DATA\n",
    "\n",
    "# What function can we use to extract the structure (# columns and # of rows) of the dataframe 'df'?\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.1.3 DUPLICATE ROWS\n",
    "\n",
    "# Use a function to identify how many duplicate records there are in the 'df' dataset\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#B.1.4 MISSING DATA\n",
    "\n",
    "#Use the right function on 'df' that will allow us to identify the number of missing data?\n",
    "\n",
    "# This method prints out information about a dataFrame including the index, dtype, columns, non-null values and memory usage\n",
    "# This method is also useful for finding out missing values in a dataset\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.2 Data Cleansing\n",
    "\n",
    "        B.2.1 Convert variables to appropriate data types \n",
    "        B.2.2 Remove duplicate rows\n",
    "        B.2.3 Interpolate using median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the script below to convert some appropriate variables using astype() method\n",
    "\n",
    "df[\"timestamp\"] = df.timestamp.astype(\"datetime64\")\n",
    "df[\"year\"] = df.year.astype(\"category\")\n",
    "df[\"season\"] = df.season.astype(\"category\")\n",
    "df[\"month\"] = df.month.astype(\"category\")\n",
    "df[\"day\"] = df.day.astype(\"category\")\n",
    "df[\"hour\"] = df.hour.astype(\"category\")\n",
    "df[\"isholiday\"] = df.isholiday.astype(\"category\")\n",
    "df[\"isweekend\"] = df.isweekend.astype(\"category\")\n",
    "df[\"weathercode\"] = df.weathercode.astype(\"category\")\n",
    "df[\"t1\"] = df.t1.astype(\"float64\")\n",
    "df[\"humidity\"] = df.humidity.astype(\"float64\")\n",
    "df[\"windspeed\"] = df.windspeed.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.2.1 - CONVERT VARIABLES TO APPROPRIATE DATA TYPES\n",
    "\n",
    "\n",
    "#Question 1: Use the approriate script to convert variable 't2' into float\n",
    "\n",
    "#Answer:\n",
    "\n",
    "\n",
    "\n",
    "#Question 2: Use the approriate script to convert variable 'bikecount' into int64\n",
    "\n",
    "#Answer:\n",
    "\n",
    "\n",
    "\n",
    "#Question 3: What function can we use to check if you were successful?\n",
    "\n",
    "#Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.2.2 - REMOVE DUPLICATE ROWS\n",
    "\n",
    "# Please remove all the duplicates from the dataset 'df' \n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# B.2.3 - INTERPOLATE USING MEDIAN\n",
    "\n",
    "# For variable 't1', use appropriate function to fill in missing values with the median\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECTION C - EXPLANATORY DATA ANALYSIS & VISUALISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.1 Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total and average bike shares for the year 2021\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.2 Distribution\n",
    "\n",
    "Calculate total and average bike shares for the following:\n",
    "\n",
    "        C.2.1 Season \n",
    "        C.2.2 Month\n",
    "        C.2.3 Day of week\n",
    "        C.2.4 Day of week for the most popular month\n",
    "        C.2.5 Calculate all descriptive stats (for numerical variables only)\n",
    "        C.2.6 Is bike shares distribution normal or skewed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.2.1 - SEASON\n",
    "# Create a report to showcase the total and average bike shares for each season. \n",
    "# And identify the season with the highest average value.\n",
    "\n",
    "#Answer: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.2.2 - MONTH\n",
    "# Create a report to showcase the total and daily average bike shares for each month.\n",
    "# And identify the month with the highest average value.\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.2.3 - DAY OF WEEK\n",
    "# Create a report to showcase the total and average bike shares for each day of the week. \n",
    "# And identify the day with the highest average value.\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.2.4 - DAY OF WEEK FOR MOST POPULAR MONTH\n",
    "# Create a report to showcase the total and average bike shares each day of week for the month with the highest average value. \n",
    "# And identify the day with the highest average value.\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.2.5 - CALCULATE ALL DESCRIPTIVE STATS (for numerical variables only)\n",
    "# Use a function to showcase all the descriptive statics for all numerical variables. \n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.2.6 Is bike shares distribution normal or skewed? \n",
    "\n",
    "#Answer: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.3 Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# C.3.1 - CORRELATION MATRIX\n",
    "\n",
    "# As part of your exploratory analysis use the right function to calculate the correlation for the numerical variables. \n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.3.2 - Note down which variables are strongly correlated.\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.4 Visualisations\n",
    "\n",
    "        C.4.1 Create a jointplot\n",
    "        C.4.2 Create a lineplot\n",
    "        C.4.3 Create a pairgrid\n",
    "        C.4.4 Note findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.4.1 - CREATE A JOINTPLOT\n",
    "\n",
    "# Use seaborn to create a jointplot that shows the datapoints between the variables 'bikecount' and 't1' \n",
    "# Please label the axis accordingly\n",
    "\n",
    "#Answer:\n",
    "\n",
    "\n",
    "#CHALLENGE: Add hue to the script above to break down the data by the variable 'season':\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# C.4.2 - CREATE A LINEPLOT\n",
    "\n",
    "# Use seaborn to create a line plot that shows 'month' in the x-axis and 'bikecount' in the y axis \n",
    "# Please label the axis accordingly\n",
    "\n",
    "#Answer:\n",
    "\n",
    "\n",
    "\n",
    "#CHALLENGE: Add hue to the script above to break down the data by the variable 'isweekend':\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.4.3 - CREATE A PAIRGRID\n",
    "# Use seaborn to plot a PairGrid with histograms and scatterplots for variables [\"t1\",\"t2\",\"humidity\",\"windspeed\",\"bikecount\"]\n",
    "# Please label the axis accordingly\n",
    "\n",
    "#Answer:\n",
    "\n",
    "\n",
    "\n",
    "#CHALLENGE: Add hue to the script above to break down the data by the variable 'season':\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C.4.4 - NOTE FINDINGS BELOW\n",
    "\n",
    "#Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECTION D - PREDICTIVE MODELLING (REGRESSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.1 PRE-PROCESSING\n",
    "\n",
    "    D.1.1\tRemove “timestamp” and “year” variables from the dataset\n",
    "    D.1.2\tEncode categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D.1.1 - REMOVE \"TIMESTAMP\" & \"YEAR\" VARIABLES\n",
    "\n",
    "# Use the right function to drop \"timestamp\" and \"year\" variables\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D.1.2 - ENCODE CATEGORICAL DATA\n",
    "\n",
    "# Create dummy variables (one-hot encoding) for the following categorical variables [\"season\",\"month\",\"day\",\"hour\",\"isholiday\",\"isweekend\",\"weathercode\"]\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.2 TRAIN/TEST SPLIT\n",
    "\n",
    "    D.2.1 Split df dataset into X & Y datasets\n",
    "    D.2.2 Perform 70:30 random split (use \"random_state=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.2.1 - Split df dataset into X & Y datasets\n",
    "\n",
    "# Filter the dataset in order to split the 'df' dataset into X & Y datasets\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.2.2 - Perform 70:30 random split (use \"random_state=1\")\n",
    "\n",
    "# Split further the 'x' and 'y' datasets data into train and test datasets. \n",
    "# Your test size should be 30% (0.3) and please use \"random_state=1\"\n",
    "# There should be 4 resulting datasets in the output - x_train, x_test, y_train, y_test\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.3 BUILD LINEAR REGRESSION\n",
    "    D.3.1 - Save the regression function \"LinearRegression()\" into a container called 'model'\n",
    "    D.3.2 - Fit the regression into the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.3.1 - Save the regression function \"LinearRegression()\" into a container called 'model'\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.3.2 - Fit the regression into the training data \n",
    "\n",
    "# use x_train and y_train to fit the regression line\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.4 EVALUATE (TRAINING DATASET)\n",
    "\n",
    "    D.4.1 Identify regression intercept\n",
    "        D.4.1a Reformat intercept into a dataframe\t\n",
    "    D.4.2 Identify regression coefficients\n",
    "        D.4.2a Reformat coefficients into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.4.1 - Identify regression intercept \n",
    "\n",
    "# Use the right function to extract intercept of the model\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.4.1a - Reformat intercept into a dataframe\n",
    "\n",
    "# The output from D.4.1 is an array format \n",
    "# Please reformat the intercept output into a dataframe for a much cleaner view \n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.4.2 - Identify regression coefficients\n",
    "\n",
    "# Use the right function to extract the coefficients of the model\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#D.4.2a - Reformat coefficients into a dataframe\n",
    "\n",
    "# The output from D.4.2 is an array \n",
    "# Please reformat the coefficients output into a dataframe for a much cleaner view \n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.5 RUN MODEL ON TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the right function from regression 'model' to predict the test dataset 'x_test'\n",
    "# Save the predictions into a container called 'y_pred'\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.6 CALCULATE R-SQUARED & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the rignt scripts to evaluate the overall model performance by showing us the Rsquared and RMSE statistics\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECTION E - INTERPRET RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA Evaluation\n",
    "\n",
    "#Answer: \n",
    "\n",
    "\n",
    "\n",
    "#Model Evaluation:\n",
    "\n",
    "#Answer: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3 - MODEL PREDICTIONS\n",
    "Now that we have a working model, please start preparing the new dataset for the model to predict and output the predictions into csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - IMPORT NEW DATA 'bike_data_new.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import data \"bike_data_new.xlsx\" and save as a dataframe called 'dfp'\n",
    "\n",
    "#Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - DATA QUALITY CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use various functions to conduct quality checks on the data\n",
    "\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION 3 - DATA CLEANSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 - REMOVE DUPLICATES\n",
    "\n",
    "# Remove all the duplicates from 'dfp' \n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 - REMOVE MISSING DATA\n",
    "\n",
    "# Remove all the null values from 'dfp'\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 - MAKE A COPY OF DATASET\n",
    "\n",
    "# Create a copy of the dataset 'dfp' and call it 'dfp_copy'. This will be used during the last stage.\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3.4 - CONVERT VARIABLES TO APPROPRIATE DATA TYPES\n",
    "# Run data conversions below as is:\n",
    "\n",
    "dfp[\"timestamp\"] = dfp.timestamp.astype(\"datetime64\")\n",
    "dfp[\"year\"] = dfp.year.astype(\"category\")\n",
    "dfp[\"month\"] = dfp.month.astype(\"category\")\n",
    "dfp[\"day\"] = dfp.day.astype(\"category\")\n",
    "dfp[\"hour\"] = dfp.hour.astype(\"category\")\n",
    "dfp[\"isholiday\"] = dfp.isholiday.astype(\"category\")\n",
    "dfp[\"weathercode\"] = dfp.weathercode.astype(\"category\")\n",
    "dfp[\"t1\"] = dfp.t1.astype(\"float64\")\n",
    "dfp[\"t2\"] = dfp.t2.astype(\"float64\")\n",
    "dfp[\"humidity\"] = dfp.humidity.astype(\"float64\")\n",
    "dfp[\"windspeed\"] = dfp.windspeed.astype(\"float64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1: Use the approriate script to convert variable 'season' into category\n",
    "\n",
    "# Answer:\n",
    "\n",
    "\n",
    "\n",
    "#Question 2: Use the approriate script to convert variable 'isweekend' into category\n",
    "\n",
    "# Answer:\n",
    "\n",
    "\n",
    "\n",
    "#Question 3: What function can we use to check if you were successful?\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION 4 - PRE-PROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>isholiday</th>\n",
       "      <th>isweekend</th>\n",
       "      <th>weathercode</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winter</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Winter</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Winter</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Winter</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>Winter</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>Winter</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>Winter</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>Winter</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>Winter</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7490 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season month day hour isholiday isweekend weathercode   t1   t2  \\\n",
       "0     Winter     1   6    6         0         1           1  3.0  0.0   \n",
       "1     Winter     1   6    7         0         1           1  3.0  0.0   \n",
       "2     Winter     1   6    8         0         1           1  3.0  0.0   \n",
       "3     Winter     1   6    9         0         1           1  4.5  1.5   \n",
       "4     Winter     1   6   10         0         1           1  5.5  2.5   \n",
       "...      ...   ...  ..  ...       ...       ...         ...  ...  ...   \n",
       "7485  Winter    12   5   18         0         0           4  4.0  2.0   \n",
       "7486  Winter    12   5   19         0         0           4  4.0  1.5   \n",
       "7487  Winter    12   5   20         0         0           4  4.0  1.5   \n",
       "7488  Winter    12   5   21         0         0           4  4.0  1.0   \n",
       "7489  Winter    12   5   22         0         0           4  5.0  2.0   \n",
       "\n",
       "      humidity  windspeed  \n",
       "0         87.0       10.0  \n",
       "1         87.0       12.0  \n",
       "2         87.0       12.0  \n",
       "3         84.0       14.0  \n",
       "4         76.0       17.0  \n",
       "...        ...        ...  \n",
       "7485     100.0        9.0  \n",
       "7486     100.0       11.0  \n",
       "7487     100.0       10.0  \n",
       "7488     100.0       12.0  \n",
       "7489      93.0       12.0  \n",
       "\n",
       "[7490 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 - REMOVE VARIABLES \"TIMESTAMP\" & \"YEAR\"\n",
    "\n",
    "# drop \"timestamp\" and \"year\" columns from 'dfp'\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 4.2 - ENCODE CATEGORICAL DATA\n",
    "\n",
    "# Create dummy variables (one-hot encoding) from the following categorical variables: [\"season\",\"month\",\"day\",\"hour\",\"isholiday\",\"isweekend\",\"weathercode\"]\n",
    "# Please save to 'dfp2'\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION 5 - PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 USE MODEL TO PREDICT BIKE SHARES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"model\" to predict dfp2 and save results to 'newbikeshares'\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 - COMBINE PREDICTED BIKE SHARE DATA FROM 5.1 WITH THE NEW DATA ('bike_data_new.xlsx')\n",
    "    5.2.1 - Reformat predictions into a dataframe called 'dfr'\n",
    "    5.2.2 - Create a new dataframe that joins dfr to the 'dfp_copy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2.1 - Reformat predictions into a dataframe called 'dfr' and name the new column \"newbikecount\"\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2.2 - Create a new dataframe 'newdf' that joins 'dfr' to the 'dfp_copy' \n",
    "#note: dataset 'dfp_copy' was saved in section 3.3 for later reference\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION F - SAVE PREDICTIONS TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the above dataframe (\"newdf\") as a csv file\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
