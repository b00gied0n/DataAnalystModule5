{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python NumPy and Pandas\n",
    "\n",
    "**What we cover:**\n",
    "1. Python NumPy library\n",
    "    - Importing NumPy library\n",
    "    - Exploring NumPy mathematical and statistical operations\n",
    "2. Python Pandas library\n",
    "    - Importing Pandas library\n",
    "    - Exploring Pandas data structures\n",
    "        - Series\n",
    "        - DataFrames\n",
    "    - Importing data from CSV files using Pandas\n",
    "    - Importing data from EXCEL files using Pandas\n",
    "    - Pandas groupby() method\n",
    "    - Subsetting or Slicing in Pandas \n",
    "        - using square brackets []\n",
    "        - logical/boolean method\n",
    "        - loc[] method\n",
    "        - iloc[] method\n",
    "    - Dealing with missing data in Pandas\n",
    "    - Dealing with duplicate data in Pandas\n",
    "    - Introduction to Joins in Pandas\n",
    "    - Introduction to Concatenation in Pandas\n",
    "\n",
    "\n",
    "</Br></Br></Br></Br></Br></Br></Br></Br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Introduction\n",
    "\n",
    "<img src=\"pics/numpy.png\" alt=\"NumPy\"\n",
    "\ttitle=\"NumPy\" \n",
    "    width=\"350\" \n",
    "    height=\"200\"\n",
    "    align=\"center\"/>\n",
    "\n",
    "\n",
    "\n",
    "- NumPy is the core library for scientific computing in Python\n",
    "- NumPy provides multidimensional array objects, and tools for working with these arrays\n",
    "- NumPy stands for Numerical Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy \"Array\" data object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NumPy provide **array** data objects (data structure) that are up to 50x faster than Python lists\n",
    "\n",
    "- NumPy arrays are called as **\"ndarray\"** (n dimensional array)\n",
    "\n",
    "- Arrays are homogeneous multidimensional structures\n",
    "\n",
    "- Arrays are grid of values, sharing the same data type, indexed by a tuple of non-negative integers\n",
    "\n",
    "- NumPy dimensions are called axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/numpy_array.png?modified=1234567\" alt=\"NumPy array\"\n",
    "\ttitle=\"NumPy array\" \n",
    "    width=\"550\" \n",
    "    height=\"400\"\n",
    "    align=\"center\"/>\n",
    "\n",
    "#### Some useful reference:\n",
    "\n",
    "[NumPy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following code can be used to install Numpy into jupyter notebook environment\n",
    "\n",
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once NumPy is installed, it can be imported to jupyter notebook by using \"import\" keyword\n",
    "# usually NumPy is imported under the alias of \"np\"\n",
    "# this is mainly done due to ease of referencing\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Current installed NumPy version can be checked by using the following code\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy ndarray object can be created by using the array() function\n",
    "# Let's create a 1D array\n",
    "\n",
    "myarray1 = np.array([11,32,45,7])\n",
    "myarray1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape attribute returns the number of dimensions found in the array data object\n",
    "# The example below returns (4,) - which means that the array has 1 dimension, and 4 elements in that dimension\n",
    "\n",
    "myarray1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing a NumPy 1D Array\n",
    "# [] - square brackets are used while slicing\n",
    "\n",
    "\n",
    "myarray1[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a 2D array\n",
    "\n",
    "myarray2 = np.array([[11,32,45,7], [88,95,22,13]])\n",
    "myarray2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape attribute returns the number of dimensions found in the array data object\n",
    "# The example below returns (2,4) - which means that the array has 2 dimensions --> 2 Rows and 4 Columns\n",
    "\n",
    "myarray2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing a NumPy 2D Array\n",
    "# [] - square brackets are used while slicing\n",
    "\n",
    "myarray2[1, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reshape() method chnages the shape of the array without changing its underlying data\n",
    "# below changes the (2, 4) 2D-array to a (4,2) 2D-array\n",
    "\n",
    "myarray2.reshape(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arange() method returns an ndarray object containing evenly spaced values\n",
    "# np.arange(start, stop, step-size) \n",
    "\n",
    "myarray3 = np.arange(1,10,2)\n",
    "myarray3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy contains a large number of mathematical  and statistical operations\n",
    "\n",
    "[Math functions](https://numpy.org/doc/stable/reference/routines.math.html)\n",
    "\n",
    "[Statistical functions](https://numpy.org/doc/stable/reference/routines.statistics.html)\n",
    "\n",
    "- In the following section let's explore few of these commonly used functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myarray4 = np.array([13, 23, 55, 67, 49])\n",
    "\n",
    "# calculate the total\n",
    "np.sum(myarray4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the median, 50th percentile, 2nd quartile\n",
    "\n",
    "np.median(myarray4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the median, 50th percentile, 2nd quartile\n",
    "\n",
    "np.quantile(myarray4, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate standard deviation\n",
    "\n",
    "np.std(myarray4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate square root\n",
    "\n",
    "np.sqrt(myarray4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Introduction\n",
    "\n",
    "<img src=\"pics/pandas.png\" alt=\"pandas\"\n",
    "\ttitle=\"pandas\" \n",
    "    width=\"350\" \n",
    "    height=\"200\"\n",
    "    align=\"center\"/>\n",
    "    \n",
    "\n",
    "- Pandas is a high-level data manipulation library. It is built on the NumPy package and provides two valuable data structures: **Series** and **DataFrame**\n",
    "\n",
    "- DataFrame allow you to store and manipulate tabular data in rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas data structures\n",
    "\n",
    "- Pandas Series is a one-dimensional labelled array capable of holding any data type with axis labels or index. An example of a Series object is one column from a DataFrame. Indexing in a panda’s series starts from 0\n",
    "\n",
    "- Pandas DataFrame is a 2-dimensional labelled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dictionary of Series objects. It is generally the most commonly used pandas’ object. Like Series, DataFrame accepts many different kinds of inputs. Indexing in a panda DataFrame starts from 0 (for both rows and columns)\n",
    "\n",
    "<img src=\"pics/pandas_series_and_dataframe.png?modified=12345678\" alt=\"series_and_dataframe\"\n",
    "\ttitle=\"series_and_dataframe\" \n",
    "    width=\"550\" \n",
    "    height=\"400\"\n",
    "    align=\"center\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "#### Some useful reference:\n",
    "\n",
    "[Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following code can be used to install Pandas into Jupyter notebook environment\n",
    "\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once Pandas is installed, it can be imported into Jupyter notebook by using \"import\" keyword\n",
    "# usually Pandas is imported under the alias of \"pd\"\n",
    "# this is mainly done due to ease of referencing\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current installed Pandas version can be checked by using the following code\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code showcases creation of a Series\n",
    "# Series is a type of a list in pandas which can take integer values, string values, double values and more \n",
    "# Pandas Series index stats from 0\n",
    "\n",
    "emp = pd.Series([\"Matt\",\"Ned\",\"John\", \"Sam\"]) \n",
    "emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring pandas series data object type\n",
    "\n",
    "type(emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series index stats from 0, use [] square bracket technique while slicing\n",
    "\n",
    "emp[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring length of the pandas series\n",
    "\n",
    "#len(emp)\n",
    "\n",
    "emp.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "<img src=\"pics/pandas_series_design.png\" alt=\"pandas Series\"\n",
    "\ttitle=\"pandas Series\" \n",
    "    width=\"100\" \n",
    "    height=\"200\"\n",
    "    align=\"left\"/>\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "\n",
    " - Write down the code to design the above Pandas Series data structure\n",
    " - Save the series as \"age1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write down the answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code showcases creation of a Dataframe\n",
    "# Pandas DataFrame is a 2-dimensional labelled data structure with columns of potentially different types\n",
    "# below code showcases how to use a dictionary (key-values) to manually create a Dataframe\n",
    "\n",
    "df = pd.DataFrame({\"SID\":[111,112,113], \"SName\":[\"Dar\",\"Nedum\",\"Don\"], \"Score\":[85,95,90]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring pandas Dataframe object type\n",
    "\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "<img src=\"pics/pandas_dataframe_design.png?modified=12345678\" alt=\"pandas\"\n",
    "\ttitle=\"pandas\" \n",
    "    width=\"350\" \n",
    "    height=\"200\"\n",
    "    align=\"left\"/>\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    " - Write down the code to design the above Dataframe structure\n",
    " - Save the Dataframe as \"car1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down the answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data with read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() function from pandas is used while importing data from CSV files\n",
    "# read_csv() function imports the as a Dataframe object\n",
    "# Pandas has now become the industry norm while working with tabular data structures\n",
    "\n",
    "house = pd.read_csv(\"HousePrices.csv\")\n",
    "house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head() can used to explore the first 5 records of the dataframe (Indexing starts from 0)\n",
    "\n",
    "house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tail() can be used to explore the last 5 records of the dataframe (Indexing starts from 0)\n",
    "\n",
    "house.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe() method is used for calculating summary statistics such as \n",
    "# count, mean, percentiles and std of the numerical values of a Series or DataFrame\n",
    "\n",
    "house.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info() method prints information about a DataFrame including the index dtype and columns, non-null values, etc\n",
    "\n",
    "house.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data with read_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_excel() function from pandas is used while importing data from excel files\n",
    "# read_excel() function imports the as a Dataframe object\n",
    "# Pandas has now become the industry norm while working with tabular data structures\n",
    "\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    " - Write down the code to import **\"Superstore.xlsx\"**\n",
    " - Save the Dataframe as **\"superstore\"**\n",
    " - Display the first 8 rows in the **\"superstore\"** dataset\n",
    " - Explore the **\"superstore\"** dataset by using describe() and info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write down the answer here:\n",
    "\n",
    "# importing superstore dataset\n",
    "\n",
    "# display the first 8 rows in the \"superstore\" dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas groupby() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function | Description   |\n",
    "|:- |:- |\n",
    "|count\t|Number of non-null observations|\n",
    "|sum\t|Sum of values|\n",
    "|mean\t|Mean of values|\n",
    "|mad\t|Mean absolute deviation|\n",
    "|median\t|Arithmetic median of values|\n",
    "|min\t|Minimum|\n",
    "|max\t|Maximum|\n",
    "|mode\t|Mode|\n",
    "|abs\t|Absolute Value|\n",
    "|prod\t|Product of values|\n",
    "|std\t|Unbiased standard deviation|\n",
    "|var\t|Unbiased variance|\n",
    "|sem\t|Unbiased standard error of the mean|\n",
    "|skew\t|Unbiased skewness (3rd moment)|\n",
    "|kurt\t|Unbiased kurtosis (4th moment)|\n",
    "|quantile\t|Sample quantile (value at %)|\n",
    "|cumsum\t|Cumulative sum|\n",
    "|cumprod\t|Cumulative product|\n",
    "|cummax\t|Cumulative maximum|\n",
    "|cummin\t|Cumulative minimum|\n",
    "\n",
    "<br><br>\n",
    "\n",
    "#### Some useful reference:\n",
    "\n",
    "[Pandas groupby() info](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#descriptive-statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's use the churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby() method can be used to group large amounts of data and compute operations on these groups\n",
    "\n",
    "churn.groupby(by=\"Gender\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby() method can be used to group large amounts of data and compute operations on these groups\n",
    "\n",
    "churn.groupby(by=\"Gender\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# groupby() method can be used to group large amounts of data and compute operations on these groups\n",
    "\n",
    "churn.groupby(by=\"Gender\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by multiple columns\n",
    "# To extend groupby() to work with multiple grouping variables, \n",
    "# pass a list of column names to groupby() instead of a single string value\n",
    "\n",
    "churn.groupby(by=[\"Gender\",\"PaymentMethod\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aggregation functionality provided by the agg() function allows multiple statistics to be calculated. \n",
    "# Instructions for aggregation are provided in the form of a python dictionary. \n",
    "# The dictionary keys are used to specify the columns upon which you would like to perform calculations, \n",
    "# and the dictionary values to specify the function to run (mean, min, max, etc)\n",
    "\n",
    "# agg() function example1\n",
    "\n",
    "churn.groupby(by=[\"Gender\",\"PaymentMethod\"]).agg({\"MonthlyCharges\": ['mean', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg() function example2\n",
    "\n",
    "churn.groupby(by=[\"Gender\",\"PaymentMethod\"]).agg({\"MonthlyCharges\": ['mean', 'min', 'max'], \"TotalCharges\": ['mean', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    " - Refer to the **churn** dataset\n",
    " - Group the data by **\"Contract\"**, **\"Churn\"**, **\"Gender\"**, and calculate count, mean, median and for **\"MonthlyCharges\"** and **\"TotalCharges\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write down the answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting or Slicing in Pandas\n",
    "\n",
    "We will be exploring four slicing techniques:\n",
    "1. Using square brackets []\n",
    "2. Using logical (boolean) expressions method\n",
    "3. Using loc[ ] method\n",
    "4. Using iloc[ ] method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Selecting columns using square brackets [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's use the churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing a pandas Dataframe\n",
    "# Select columns using [] square brackets\n",
    "# With square brackets, you can select one or more columns\n",
    "# With single set of [] square brackets, slicing output will be a pandas series\n",
    "\n",
    "churn[\"Tenure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With double set of [] square brackets, slicing output will be a pandas Dataframe\n",
    "\n",
    "churn[[\"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Select multiple columns use double set of [] square brackets\n",
    "# output is a pandas Dataframe\n",
    "\n",
    "churn[[\"Gender\",\"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Selecting rows and columns using logical (boolean) expressions method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's use the churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below slicing is done through logical (boolean) expressions method\n",
    "# The second set of [] square brackets will be used to define the logical expression (churn.Tenure>40) to filter the rows\n",
    "# The below code will output all rows where \"Tenure\" is greater than 40 and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn[churn.Tenure>40][[\"Gender\",\"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code will output all rows where \"Tenure\" is greater than 40 OR \"Gender\" is male, and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn[(churn.Tenure>40) | (churn.Gender == \"Male\")][[\"Gender\",\"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code will output all rows where \"Tenure\" is greater than 40 AND \"Gender\" is male, and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn[(churn.Tenure>40) & (churn.Gender == \"Male\")][[\"Gender\",\"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    " - Refer to the **churn** dataset\n",
    " - Extract **\"Contract\"**, **\"Churn\"**, **\"Gender\"**, **\"MonthlyCharges\"**, **\"TotalCharges\"** columns\n",
    "  - Extract only the records where **\"Churn\"** is \"Yes\", and **\"Gender\"** is \"Female\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down the answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting rows and columns using loc[ ] method\n",
    "- The pandas attribute .loc will allow you to select rows and columns in the following fasion\n",
    "\n",
    "<img src=\"pics/pandasloc.png?modified=12345678\" alt=\"pandasloc\"\n",
    "\ttitle=\"pandasloc\" \n",
    "    width=\"550\" \n",
    "    height=\"400\"\n",
    "    align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's use the churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code will output the first 5 rows and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn.loc[0:4 , [\"Gender\", \"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The below code will output all rows and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn.loc[ : , [\"Gender\", \"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code will output all rows where \"Tenure\" is greater than 40 and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn.loc[churn.Tenure>40 , [\"Gender\",\"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The below code will output all rows where \"Tenure\" is greater than 40 OR \"Gender\" is male, and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn.loc[(churn.Tenure>40) | (churn.Gender == \"Male\") , [\"Gender\",\"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The below code will output all rows where \"Tenure\" is greater than 40 AND \"Gender\" is male, and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn.loc[ (churn.Tenure>40) & (churn.Gender == \"Male\") , [\"Gender\",\"Tenure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    " - Refer to the **churn** dataset\n",
    " - Extract **\"Contract\"**, **\"Churn\"**, **\"Gender\"**, **\"MonthlyCharges\"**, **\"TotalCharges\"** columns\n",
    " - Extract only the records where **\"Churn\"** is \"Yes\", and **\"Gender\"** is \"Female\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down the answer here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Selecting rows and columns using iloc[ ] method\n",
    "- The pandas attribute .iloc will allow you to select rows and columns in the following fasion\n",
    "\n",
    "<img src=\"pics/pandasiloc.png?modified=12345678\" alt=\"pandasiloc\"\n",
    "\ttitle=\"pandasiloc\" \n",
    "    width=\"550\" \n",
    "    height=\"400\"\n",
    "    align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's use the churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code will output the first 5 rows and first 3 columns\n",
    "\n",
    "churn.iloc[0:4 , 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code will output the first 5 rows and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn.iloc[0:4 , [1,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code will output all rows and \"Gender\", \"Tenure\" columns\n",
    "\n",
    "churn.iloc[ : , [1,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data\n",
    "\n",
    "- Missing Data can occur when no information is provided \n",
    "- In Pandas missing data is represented by two value: **None** and **NaN** (an acronym for Not a Number), None and NaN as essentially interchangeable for indicating missing or null values \n",
    "\n",
    "There are several useful functions for detecting, removing, and replacing null values in Pandas DataFrame. These function can also be used in Pandas Series:\n",
    "\n",
    "- isnull()\n",
    "- notnull()\n",
    "- dropna()\n",
    "- fillna()\n",
    "- replace()\n",
    "- interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's use the churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnull() function returns the Boolean form of dataframe, which will indicate True or False for all values\n",
    "\n",
    "pd.isnull(churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating boolean series, True or False values for information in \"Tenure\" column\n",
    "\n",
    "bool_series = pd.isnull(churn[\"Tenure\"])\n",
    "bool_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering data to displaying only with \"Tenure\" = NaN (True)\n",
    "churn[bool_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dropping all missing(NaN) values from the dataframe using dropna() function   \n",
    "churn.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in missing values with a zero, using fillna() \n",
    "\n",
    "churn.fillna(0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling a missing value with previous value\n",
    "\n",
    "churn.fillna(method ='ffill', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling a missing value with after value\n",
    "\n",
    "churn.fillna(method ='bfill', inplace=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing all NaN values in the dataframe with with zeros\n",
    "\n",
    "churn.replace(to_replace = np.nan, value = 0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate missing values using linear regression\n",
    "\n",
    "churn.interpolate(method ='linear', limit_direction ='forward', inplace=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "Using the appropriate function filter and display only the whole records (not null) in the **“churn”** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's use the churn dataset\n",
    "churn = pd.read_excel(\"Telco Customer Churn - Training Dataset.xlsx\", sheet_name=\"Telco Customer Churn\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down the answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Duplicate Data in Pandas\n",
    "A common task in data analysis is dealing with duplicate values.\n",
    "- duplicated() function can detect duplicates.\n",
    "- drop_duplicates() function can remove duplicate rows.\n",
    "- Let's explore these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's use the CustomerInfo dataset\n",
    "ci = pd.read_excel(\"CustomerInfo5.xlsx\")\n",
    "ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s use duplicated() function to identify how many duplicate records there are in the dataset\n",
    "ci.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s use drop_duplicates() function to remove all the duplicates from the dataset\n",
    "ci_new = ci.drop_duplicates()\n",
    "ci_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "- Refer to the **\"SalesInfoApril\"** dataset\n",
    "- Identify how many duplicates there are in the dataset\n",
    "- Using suitable functions remove all duplicate rows\n",
    "- Save this information into a new dataset called **\"NewSalesInfoApril\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's import the \"CustomerInfo\" dataset\n",
    "SalesInfoApril = pd.read_excel(\"SalesInfoApril.xlsx\")\n",
    "SalesInfoApril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down the answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Joins in Pandas\n",
    "\n",
    "A join is used to combine rows from two tables (TableA and TableB), based on a common column between them. \n",
    "<br>\n",
    "Below outlines the four main types of Joins used during data manipulation activities:\n",
    "\n",
    "\n",
    "**Left Join():**\n",
    "return all rows from TableA, and all columns from TableA and TableB. \n",
    "Rows in TableA with no match in TableB will have \"NA\" values in the new columns. \n",
    "If there are multiple matches between TableA and TableB, all combinations of the matches are returned.\n",
    " \n",
    "**Right Join():**\n",
    "return all rows from TableB, and all columns from TableA and TableB. \n",
    "Rows in TableB with no match in TableA will have NA values in the new columns. \n",
    "If there are multiple matches between TableA and TableB, all combinations of the matches are returned.\n",
    "\n",
    "**Inner Join():**\n",
    "return all rows from TableA where there are matching values in TableB, and all columns from TableA and TableB. \n",
    "If there are multiple matches between TableA and TableB, all combination of the matches are returned.\n",
    " \n",
    "**Full Join():**\n",
    "return all rows and all columns from both TableA and TableB. \n",
    "Where there are no matching values, returns \"NA\".\n",
    "<br>\n",
    "\n",
    "<img src=\"pics/Pythonjoins.png?modified=12345678\" alt=\"Pythonjoins\"\n",
    "\ttitle=\"Pythonjoins\" \n",
    "    width=\"350\" \n",
    "    height=\"400\"\n",
    "    align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this lab, let’s use \"CustomerInfo\" and \"OrderInfo\" datasets. \n",
    "# Let’s combine these two datasets in a meaningful manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's import the \"CustomerInfo\" dataset\n",
    "CustomerInfo = pd.read_excel(\"CustomerInfo.xlsx\")\n",
    "print(CustomerInfo.head())\n",
    "\n",
    "# Let's import the \"OrderInfo\" dataset\n",
    "OrderInfo = pd.read_excel(\"OrderInfo.xlsx\")\n",
    "print(OrderInfo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let’s combine the datasets\n",
    "\n",
    "# Let's do a left join, this is defined by how=\"left\" \n",
    "# use \"CustomerID\" and \"CusID\" columns as the common column\n",
    "\n",
    "left_join_df = pd.merge(CustomerInfo, \n",
    "                        OrderInfo, \n",
    "                        how=\"left\", \n",
    "                        left_on=\"CustomerID\", \n",
    "                        right_on=\"CusID\")\n",
    "\n",
    "\n",
    "left_join_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a right join, this is defined by how=\"right\" \n",
    "# use \"CustomerID\" and \"CusID\" columns as the common column\n",
    "\n",
    "right_join_df = pd.merge(CustomerInfo, \n",
    "                        OrderInfo, \n",
    "                        how=\"right\", \n",
    "                        left_on=\"CustomerID\", \n",
    "                        right_on=\"CusID\")\n",
    "\n",
    "\n",
    "right_join_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a inner join, this is defined by how=\"inner\" \n",
    "# use \"CustomerID\" and \"CusID\" columns as the common column\n",
    "\n",
    "inner_join_df = pd.merge(CustomerInfo, \n",
    "                        OrderInfo, \n",
    "                        how=\"inner\", \n",
    "                        left_on=\"CustomerID\", \n",
    "                        right_on=\"CusID\")\n",
    "\n",
    "\n",
    "inner_join_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a full join, this is defined by how=\"outer\" \n",
    "# use \"CustomerID\" and \"CusID\" columns as the common column\n",
    "\n",
    "full_join_df = pd.merge(CustomerInfo, \n",
    "                        OrderInfo, \n",
    "                        how=\"outer\", \n",
    "                        left_on=\"CustomerID\", \n",
    "                        right_on=\"CusID\")\n",
    "\n",
    "\n",
    "full_join_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to  Concatenation in Pandas\n",
    "- Concatenation combines or appends all rows from the tables, also known as “Set Operations” or “Unions”.\n",
    "- Concatenated data may sometimes contain duplicates, with additional functionalities duplicate can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this lab, let’s use \"CustomerInfo\" and \"CustomerInfo2\" datasets. \n",
    "\n",
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Let's import the \"CustomerInfo\" dataset\n",
    "CustomerInfo = pd.read_excel(\"CustomerInfo.xlsx\")\n",
    "print(CustomerInfo.head())\n",
    "\n",
    "# Let's import the \"CustomerInfo2\" dataset\n",
    "CustomerInfo2 = pd.read_excel(\"CustomerInfo2.xlsx\")\n",
    "print(CustomerInfo2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s concatenate \"CustomerInfo\" and \"CustomerInfo2\" datasets in a meaningful manner\n",
    "# Please note the output contain duplicate rows\n",
    "\n",
    "all_rows = pd.concat([CustomerInfo, CustomerInfo2])\n",
    "all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's remove duplicates using drop_duplicates()\n",
    "\n",
    "all_rows.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "- Refer to the **\"SalesInfoJan\"**, **\"SalesInfoFeb\"** and  **\"ProductInfo\"** datasets.\n",
    "- Using appropriate pandas functons combine **\"SalesInfoJan\"** and **\"SalesInfoFeb\"** datasets\n",
    "- Save this information into a new dataset called **\"SalesInfo\"**\n",
    "- Now merge/join **\"SalesInfo\"** with  **\"ProductInfo\"** dataset\n",
    "- Save this information into a new dataset called **\"AllSales\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas library with the alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Importing all datasets\n",
    "SalesInfoJan = pd.read_excel(\"SalesInfoJan.xlsx\")\n",
    "SalesInfoFeb = pd.read_excel(\"SalesInfoFeb.xlsx\")\n",
    "ProductInfo = pd.read_excel(\"ProductInfo.xlsx\")\n",
    "\n",
    "print(SalesInfoJan.head())\n",
    "\n",
    "print(SalesInfoFeb.head())\n",
    "\n",
    "print(ProductInfo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down the answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
