{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis using WordClouds\n",
    "\n",
    "#### What is Text analysis?\n",
    "\n",
    "- Text analysis is the process of examining large collections of unstructured textual data, in order to generate new information. Text analysis is also known as \"Text Mining\".\n",
    "\n",
    "- The Word cloud model (also known as bag of words model) is a way of extracting features (words) from text, it describes the occurrence of words within a document."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Goal\n",
    "The goal of this lab is to produce a Wordcloud to analyse customer feedback survey data. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the dataset\n",
    "For this lab we will use the \"ConsumerSentiment.xlsx\" dataset. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Install Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install scikit-learn\n",
    "#!pip install scipy\n",
    "#!pip install seaborn\n",
    "#!pip install matplotlib\n",
    "#!pip install nltk\n",
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with loading all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process map\n",
    "Below illustrates a 5-step process used during this lab.\n",
    "\n",
    "    1. Import Data\n",
    "    2. Data Quality Checks\n",
    "    3. Data Cleansing\n",
    "    4. Data Pre-processing\n",
    "    5. Visualisations\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from a Excel file and saving that data into a dataframe called \"df\"\n",
    "\n",
    "df = pd.read_excel(\"ConsumerSentiment.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Quality Checks\n",
    "\n",
    "    2.1 Check data\n",
    "    2.2 Check shape of data\n",
    "    2.3 Check for duplicates\n",
    "    2.4 Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "# Viewing top 5 records\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2\n",
    "# Looking at the structure of the dataframe\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3\n",
    "# Letâ€™s use duplicated() function to identify how many duplicate records there are in the dataset\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2.4\n",
    "# This method prints out information about a dataframe including the index, dtype, columns, non-null values and memory usage\n",
    "# This method is also useful for finding out missing values in a dataset\n",
    "# if found, we can use interpolation techniques to rectify those missing values\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you remove all the duplicates from the dataset using drop_duplicates() function\n",
    "\n",
    "# df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Data Pre-processing\n",
    "\n",
    "    4.1 Create the stopwords list\n",
    "    4.2 create a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1\n",
    "# Create the stopwords list object called \"sw\"\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "sw = set(STOPWORDS)\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding custom words to the stopwords list \"sw\"\n",
    "sw.update([\"drink\", \"now\", \"flavour\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2\n",
    "# combining all customer reviews to create a corpus\n",
    "# this corpus will be used during the wordcloud generation process\n",
    "\n",
    "\n",
    "# Converting Data in \"Text\" column to string\n",
    "df[\"Text\"] = df.Text.astype(str)\n",
    "\n",
    "\n",
    "# Joining all reviews from \"Text\" column to one big text corpus --> this new object is called \"tc\"\n",
    "tc = \" \".join(n for n in df.Text)\n",
    "\n",
    "\n",
    "# Count the total number of words in the corpus\n",
    "print (\"There are {} words in the corpus\".format(len(tc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the text corpus \"tc\" --> let's look at first 1000 characters\n",
    "tc[0:1000]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the wordcloud object called \"wd\"\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wd = WordCloud(stopwords=sw,\n",
    "               max_font_size=30, \n",
    "               max_words=100,\n",
    "               random_state=45,\n",
    "               background_color=\"white\").generate(tc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the wordcloud using matplotlib\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wd)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the wordcloud as an image to the default working directory\n",
    "wd.to_file(\"CustomerSentimentWordCloud.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find out the default working directory\n",
    "# import os\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
