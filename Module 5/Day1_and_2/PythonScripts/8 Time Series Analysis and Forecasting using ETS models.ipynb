{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis and Forecasting using ETS model\n",
    "\n",
    "- Time series analysis is all about understanding of the given historical data, in order to extract meaningful statistics, patterns and other characteristics, forecasting is to predict its future behaviour"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Goal\n",
    "The goal of this lab is to forecast future values with \"AirPassengers\" dataset, using ETS forecasting technique."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the \"AirPassengers\" dataset\n",
    "Airline data showing monthly totals of international airline passengers, from 1949 to 1960"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Install Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install scikit-learn\n",
    "#!pip install scipy\n",
    "#!pip install seaborn\n",
    "#!pip install matplotlib\n",
    "#!pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# these two lines of code needs to be run when using pandas dataframes within matplotlib\n",
    "# if not, you would get some warning/error messages\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "\n",
    "# Switching off unnecessary warning messages \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process map\n",
    "Below illustrates a 9-step process used during this lab.\n",
    "\n",
    "    1.\tImport Data\n",
    "    2.\tData Quality Checks\n",
    "    3.\tData Cleansing\n",
    "    4.\tData Pre-processing\n",
    "    5.\tVisualisations\n",
    "    6.\tModel: Build\n",
    "    7.\tModel: Evaluation\n",
    "    8.\tModel: Predictions\n",
    "    9.\tModel: Save Predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from a Excel file and saving that data into a dataframe called \"df\"\n",
    "df = pd.read_excel(\"AirPassengers.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Quality Checks\n",
    "\n",
    "    2.1 Check data\n",
    "    2.2 Check shape of data\n",
    "    2.3 Check for duplicates\n",
    "    2.4 Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "# Viewing top 5 records\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2\n",
    "# Looking at the structure of the dataframe\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3\n",
    "# Let’s use duplicated() function to identify how many duplicate records there are in the dataset\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4\n",
    "# This method prints out information about a dataframe including the index, dtype, columns, non-null values and memory usage\n",
    "# This method is also useful for finding out missing values in a dataset\n",
    "# if found, we can use interpolation techniques to rectify those missing values\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Cleansing\n",
    "\n",
    "    3.1 Remove duplicates\n",
    "    3.2 Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1\n",
    "# This is how you remove all the duplicates from the dataset using drop_duplicates() function\n",
    "\n",
    "# df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2\n",
    "# Fill missing values (NaN, Null) with median value of a column\n",
    "\n",
    "# This is how you fix a missing value for a specific column\n",
    "# df.Passengers = df.Passengers.fillna(df.Passengers.median())\n",
    "# df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently the \"df\" is a dataframe object, but for time-series analysis this data needs to be reformatted.\n",
    "\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the time-series object\n",
    "#### Step1:\n",
    "- It is good practice to create an index to explain the behaviour of the time-series, \n",
    "- This is mainly done as a support measure to further explain the frequency of the time-series. \n",
    "- Think of this as a better formatted version of the” Datestamps”. \n",
    "- Index will be used during model building stage.\n",
    "\n",
    "\n",
    "[Learn more about different time-series frequencies found in python] (https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = pd.date_range(start ='1949-01-01', freq ='MS', periods = 144)\n",
    "dti"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a pandas time-series object using \"dti\" index \n",
    "\n",
    "df2 = pd.Series(data=list(df.Passengers), index=dti)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see this new \"df2\" is no longer a dataframe object, it's a series object\n",
    "\n",
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a lineplot using matplotlib package\n",
    "\n",
    "plt.plot(df2)\n",
    "plt.title(\"Air passenger analysis\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Passengers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a lineplot using seaborn package\n",
    "\n",
    "sns.lineplot(data=df2)\n",
    "plt.title(\"Air passenger analysis\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Model: Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the ETS Model using ExponentialSmoothing() function\n",
    "\n",
    "model = ExponentialSmoothing(df2, seasonal_periods=12, trend='add', seasonal='mul', freq=\"MS\", dates=dti)\n",
    "fit1 = model.fit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Model: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Model: Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for 12 months\n",
    "\n",
    "passengers_forecast = fit1.forecast(steps=12)\n",
    "passengers_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualising the forecasted values in a line chart\n",
    "\n",
    "# creating the line chart object using matplotlib\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Air Passengers')\n",
    "\n",
    "# creating two charts to show actual and forecasted values\n",
    "Actual, = plt.plot(df2.index, df2, 'blue', label='Actual')\n",
    "predicted, = plt.plot(passengers_forecast.index, passengers_forecast, 'red', label='Forecast')\n",
    "\n",
    "plt.legend(handles=[Actual, predicted])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Model: Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Predictions to a CSV file\n",
    "\n",
    "passengers_forecast.to_csv(\"AirPassengersPredicted.csv\", header=False, index=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
